{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import metrics\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis as QDA\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadData():\n",
    "    train_data = pd.read_csv('train.csv')\n",
    "    test_data = pd.read_csv('test.csv',header=None)\n",
    "    train_label = pd.read_csv('trainLabels.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_Classifier(train_data,train_label,test_data):  \n",
    "    knn = KNeighborsClassifier(n_neighbors=10)            ### k = 10 (number of neighbours)\n",
    "    knn.fit(train_data,np.ravel(train_label))\n",
    "    test_label = knn.predict(test_data)\n",
    "    return test_label\n",
    "\n",
    "#KNN_Classifier(train_data,train_label,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GaussianNB_Classifier(train_data,train_label,test_data):\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.4, random_state=1)\n",
    "    gnb = GaussianNB()\n",
    "    gnb.fit(train_data, np.ravel(train_label))\n",
    "    test_label = gnb.predict(test_data)\n",
    "    #print(\"Gaussian Naive Bayes model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n",
    "    return test_label\n",
    "\n",
    "#GaussianNB_Classifier(train_data,train_label,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SVM_Classifier(train_data,train_label,test_data):\n",
    "    #X_train, X_test, y_train, y_test = train_test_split(train_data, train_label, test_size=0.4, random_state=1)\n",
    "    svmCl = svm.SVC(gamma=0.277777777778,C=[1000000])     # kernel =  radial (rbf,circle) ...     and C larger  \n",
    "    svmCl.fit(train_data,np.ravel(train_label))\n",
    "    pred = svmCl.predict(test_data)\n",
    "    #print(\"SVM model accuracy(in %):\", metrics.accuracy_score(y_test, y_pred)*100)\n",
    "    return pred\n",
    "\n",
    "#SVM_Classifier(train_data,train_label,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RandomForest_Classifier(train_data,train_label,test_data):\n",
    "    rf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "    clf = GridSearchCV(rf, param_grid=dict( ),verbose=3,scoring='accuracy',cv=10)\n",
    "    clf.fit(train_data,np.ravel(train_label));\n",
    "    pred = clf.predict(test_data)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QDA_Classifier(train_data,train_label,test_data):\n",
    "    clf = QDA()\n",
    "    clf.fit(train_data,np.ravel(train_label));\n",
    "    pred = clf.predict(test_data)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_CSV(pred):\n",
    "    df_test_label = pd.DataFrame(pred,columns = [\"Solution\"])\n",
    "    df_test_label.index+=1\n",
    "    df_test_label.to_csv(\"result.csv\",index_label=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.29940251144353242</th>\n",
       "      <th>-1.2266241875260637</th>\n",
       "      <th>1.4984250500215328</th>\n",
       "      <th>-1.1761503610375272</th>\n",
       "      <th>5.2898525545597037</th>\n",
       "      <th>0.20829711393323402</th>\n",
       "      <th>2.4044983672405826</th>\n",
       "      <th>1.5945062220589785</th>\n",
       "      <th>-0.051608163273514231</th>\n",
       "      <th>0.66323431039687908</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.85046544625016463</th>\n",
       "      <th>-0.62298999638261954</th>\n",
       "      <th>-1.8330573433160038</th>\n",
       "      <th>0.29302438506869571</th>\n",
       "      <th>3.5526813410266507</th>\n",
       "      <th>0.71761099417552265</th>\n",
       "      <th>3.3059719748508889</th>\n",
       "      <th>-2.7155588147154619</th>\n",
       "      <th>-2.6824085866346223</th>\n",
       "      <th>0.10105047232890663</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.174176</td>\n",
       "      <td>0.332157</td>\n",
       "      <td>0.949919</td>\n",
       "      <td>-1.285328</td>\n",
       "      <td>2.199061</td>\n",
       "      <td>-0.151268</td>\n",
       "      <td>-0.427039</td>\n",
       "      <td>2.619246</td>\n",
       "      <td>-0.765884</td>\n",
       "      <td>-0.093780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.819750</td>\n",
       "      <td>0.012037</td>\n",
       "      <td>2.038836</td>\n",
       "      <td>0.468579</td>\n",
       "      <td>-0.517657</td>\n",
       "      <td>0.422326</td>\n",
       "      <td>0.803699</td>\n",
       "      <td>1.213219</td>\n",
       "      <td>1.382932</td>\n",
       "      <td>-1.817761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.192222</td>\n",
       "      <td>-0.414371</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>-2.233568</td>\n",
       "      <td>3.658881</td>\n",
       "      <td>0.089007</td>\n",
       "      <td>0.203439</td>\n",
       "      <td>-4.219054</td>\n",
       "      <td>-1.184919</td>\n",
       "      <td>-1.240310</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.604501</td>\n",
       "      <td>0.750054</td>\n",
       "      <td>-3.360521</td>\n",
       "      <td>0.856988</td>\n",
       "      <td>-2.751451</td>\n",
       "      <td>-1.582735</td>\n",
       "      <td>1.672246</td>\n",
       "      <td>0.656438</td>\n",
       "      <td>-0.932473</td>\n",
       "      <td>2.987436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.573270</td>\n",
       "      <td>-0.580318</td>\n",
       "      <td>-0.866332</td>\n",
       "      <td>-0.603812</td>\n",
       "      <td>3.125716</td>\n",
       "      <td>0.870321</td>\n",
       "      <td>-0.161992</td>\n",
       "      <td>4.499666</td>\n",
       "      <td>1.038741</td>\n",
       "      <td>-1.092716</td>\n",
       "      <td>...</td>\n",
       "      <td>1.022959</td>\n",
       "      <td>1.275598</td>\n",
       "      <td>-3.480110</td>\n",
       "      <td>-1.065252</td>\n",
       "      <td>2.153133</td>\n",
       "      <td>1.563539</td>\n",
       "      <td>2.767117</td>\n",
       "      <td>0.215748</td>\n",
       "      <td>0.619645</td>\n",
       "      <td>1.883397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.613071</td>\n",
       "      <td>-0.644204</td>\n",
       "      <td>1.112558</td>\n",
       "      <td>-0.032397</td>\n",
       "      <td>3.490142</td>\n",
       "      <td>-0.011935</td>\n",
       "      <td>1.443521</td>\n",
       "      <td>-4.290282</td>\n",
       "      <td>-1.761308</td>\n",
       "      <td>0.807652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.513906</td>\n",
       "      <td>-1.803473</td>\n",
       "      <td>0.518579</td>\n",
       "      <td>-0.205029</td>\n",
       "      <td>-4.744566</td>\n",
       "      <td>-1.520015</td>\n",
       "      <td>1.830651</td>\n",
       "      <td>0.870772</td>\n",
       "      <td>-1.894609</td>\n",
       "      <td>0.408332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.773247</td>\n",
       "      <td>-0.123227</td>\n",
       "      <td>0.047423</td>\n",
       "      <td>-0.210266</td>\n",
       "      <td>10.377793</td>\n",
       "      <td>0.526604</td>\n",
       "      <td>-2.751616</td>\n",
       "      <td>0.315541</td>\n",
       "      <td>0.608603</td>\n",
       "      <td>-0.043421</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.487714</td>\n",
       "      <td>0.792790</td>\n",
       "      <td>-0.540711</td>\n",
       "      <td>0.114115</td>\n",
       "      <td>-0.277477</td>\n",
       "      <td>-0.896411</td>\n",
       "      <td>-2.805207</td>\n",
       "      <td>0.469162</td>\n",
       "      <td>3.614157</td>\n",
       "      <td>0.081689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   0.29940251144353242  -1.2266241875260637  1.4984250500215328  \\\n",
       "0            -1.174176             0.332157            0.949919   \n",
       "1             1.192222            -0.414371            0.067054   \n",
       "2             1.573270            -0.580318           -0.866332   \n",
       "3            -0.613071            -0.644204            1.112558   \n",
       "4            -0.773247            -0.123227            0.047423   \n",
       "\n",
       "   -1.1761503610375272  5.2898525545597037  0.20829711393323402  \\\n",
       "0            -1.285328            2.199061            -0.151268   \n",
       "1            -2.233568            3.658881             0.089007   \n",
       "2            -0.603812            3.125716             0.870321   \n",
       "3            -0.032397            3.490142            -0.011935   \n",
       "4            -0.210266           10.377793             0.526604   \n",
       "\n",
       "   2.4044983672405826  1.5945062220589785  -0.051608163273514231  \\\n",
       "0           -0.427039            2.619246              -0.765884   \n",
       "1            0.203439           -4.219054              -1.184919   \n",
       "2           -0.161992            4.499666               1.038741   \n",
       "3            1.443521           -4.290282              -1.761308   \n",
       "4           -2.751616            0.315541               0.608603   \n",
       "\n",
       "   0.66323431039687908         ...           -0.85046544625016463  \\\n",
       "0            -0.093780         ...                      -0.819750   \n",
       "1            -1.240310         ...                      -0.604501   \n",
       "2            -1.092716         ...                       1.022959   \n",
       "3             0.807652         ...                       0.513906   \n",
       "4            -0.043421         ...                      -1.487714   \n",
       "\n",
       "   -0.62298999638261954  -1.8330573433160038  0.29302438506869571  \\\n",
       "0              0.012037             2.038836             0.468579   \n",
       "1              0.750054            -3.360521             0.856988   \n",
       "2              1.275598            -3.480110            -1.065252   \n",
       "3             -1.803473             0.518579            -0.205029   \n",
       "4              0.792790            -0.540711             0.114115   \n",
       "\n",
       "   3.5526813410266507  0.71761099417552265  3.3059719748508889  \\\n",
       "0           -0.517657             0.422326            0.803699   \n",
       "1           -2.751451            -1.582735            1.672246   \n",
       "2            2.153133             1.563539            2.767117   \n",
       "3           -4.744566            -1.520015            1.830651   \n",
       "4           -0.277477            -0.896411           -2.805207   \n",
       "\n",
       "   -2.7155588147154619  -2.6824085866346223  0.10105047232890663  \n",
       "0             1.213219             1.382932            -1.817761  \n",
       "1             0.656438            -0.932473             2.987436  \n",
       "2             0.215748             0.619645             1.883397  \n",
       "3             0.870772            -1.894609             0.408332  \n",
       "4             0.469162             3.614157             0.081689  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()        ##### No idea what this is.. (Finally kaggle said this is just random data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.29940251144353242</th>\n",
       "      <th>-1.2266241875260637</th>\n",
       "      <th>1.4984250500215328</th>\n",
       "      <th>-1.1761503610375272</th>\n",
       "      <th>5.2898525545597037</th>\n",
       "      <th>0.20829711393323402</th>\n",
       "      <th>2.4044983672405826</th>\n",
       "      <th>1.5945062220589785</th>\n",
       "      <th>-0.051608163273514231</th>\n",
       "      <th>0.66323431039687908</th>\n",
       "      <th>...</th>\n",
       "      <th>-0.85046544625016463</th>\n",
       "      <th>-0.62298999638261954</th>\n",
       "      <th>-1.8330573433160038</th>\n",
       "      <th>0.29302438506869571</th>\n",
       "      <th>3.5526813410266507</th>\n",
       "      <th>0.71761099417552265</th>\n",
       "      <th>3.3059719748508889</th>\n",
       "      <th>-2.7155588147154619</th>\n",
       "      <th>-2.6824085866346223</th>\n",
       "      <th>0.10105047232890663</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "      <td>999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.025322</td>\n",
       "      <td>-0.023323</td>\n",
       "      <td>-0.025612</td>\n",
       "      <td>-0.001096</td>\n",
       "      <td>1.088127</td>\n",
       "      <td>-0.006465</td>\n",
       "      <td>0.495433</td>\n",
       "      <td>-0.039517</td>\n",
       "      <td>0.026469</td>\n",
       "      <td>-0.004264</td>\n",
       "      <td>...</td>\n",
       "      <td>0.031533</td>\n",
       "      <td>0.023598</td>\n",
       "      <td>-0.541199</td>\n",
       "      <td>-0.011913</td>\n",
       "      <td>-0.487548</td>\n",
       "      <td>0.032686</td>\n",
       "      <td>0.564443</td>\n",
       "      <td>0.009574</td>\n",
       "      <td>-0.890867</td>\n",
       "      <td>0.609960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.008750</td>\n",
       "      <td>1.016094</td>\n",
       "      <td>0.978412</td>\n",
       "      <td>0.970349</td>\n",
       "      <td>4.539161</td>\n",
       "      <td>0.989601</td>\n",
       "      <td>2.119020</td>\n",
       "      <td>2.232776</td>\n",
       "      <td>1.001562</td>\n",
       "      <td>1.013808</td>\n",
       "      <td>...</td>\n",
       "      <td>1.011767</td>\n",
       "      <td>1.001668</td>\n",
       "      <td>2.240688</td>\n",
       "      <td>1.022922</td>\n",
       "      <td>2.118491</td>\n",
       "      <td>1.007316</td>\n",
       "      <td>2.227304</td>\n",
       "      <td>0.994404</td>\n",
       "      <td>2.022240</td>\n",
       "      <td>2.046400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-3.365711</td>\n",
       "      <td>-3.492086</td>\n",
       "      <td>-2.695602</td>\n",
       "      <td>-3.460471</td>\n",
       "      <td>-16.421901</td>\n",
       "      <td>-3.041250</td>\n",
       "      <td>-7.224761</td>\n",
       "      <td>-6.509084</td>\n",
       "      <td>-3.145588</td>\n",
       "      <td>-2.749812</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.379194</td>\n",
       "      <td>-2.971125</td>\n",
       "      <td>-7.840890</td>\n",
       "      <td>-2.999564</td>\n",
       "      <td>-7.124105</td>\n",
       "      <td>-2.952358</td>\n",
       "      <td>-5.452254</td>\n",
       "      <td>-3.473913</td>\n",
       "      <td>-8.051722</td>\n",
       "      <td>-7.799086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-0.670358</td>\n",
       "      <td>-0.690859</td>\n",
       "      <td>-0.700048</td>\n",
       "      <td>-0.616548</td>\n",
       "      <td>-1.805683</td>\n",
       "      <td>-0.733114</td>\n",
       "      <td>-0.839542</td>\n",
       "      <td>-1.607010</td>\n",
       "      <td>-0.680114</td>\n",
       "      <td>-0.682246</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.659295</td>\n",
       "      <td>-0.696257</td>\n",
       "      <td>-2.123069</td>\n",
       "      <td>-0.664966</td>\n",
       "      <td>-1.880040</td>\n",
       "      <td>-0.643513</td>\n",
       "      <td>-1.060154</td>\n",
       "      <td>-0.689890</td>\n",
       "      <td>-2.214672</td>\n",
       "      <td>-0.565156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.023121</td>\n",
       "      <td>-0.031181</td>\n",
       "      <td>0.008037</td>\n",
       "      <td>0.003735</td>\n",
       "      <td>0.858932</td>\n",
       "      <td>0.025803</td>\n",
       "      <td>0.571475</td>\n",
       "      <td>0.017761</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>-0.037531</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049792</td>\n",
       "      <td>0.050187</td>\n",
       "      <td>-0.568168</td>\n",
       "      <td>-0.028179</td>\n",
       "      <td>-0.493701</td>\n",
       "      <td>0.036975</td>\n",
       "      <td>0.453544</td>\n",
       "      <td>0.038464</td>\n",
       "      <td>-0.853259</td>\n",
       "      <td>0.780175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.762980</td>\n",
       "      <td>0.683464</td>\n",
       "      <td>0.657948</td>\n",
       "      <td>0.640968</td>\n",
       "      <td>3.836911</td>\n",
       "      <td>0.671494</td>\n",
       "      <td>1.912284</td>\n",
       "      <td>1.436715</td>\n",
       "      <td>0.741949</td>\n",
       "      <td>0.666416</td>\n",
       "      <td>...</td>\n",
       "      <td>0.747815</td>\n",
       "      <td>0.700093</td>\n",
       "      <td>0.940334</td>\n",
       "      <td>0.651692</td>\n",
       "      <td>0.997741</td>\n",
       "      <td>0.690139</td>\n",
       "      <td>2.120006</td>\n",
       "      <td>0.693603</td>\n",
       "      <td>0.390982</td>\n",
       "      <td>1.994308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.326246</td>\n",
       "      <td>3.583870</td>\n",
       "      <td>2.546507</td>\n",
       "      <td>3.088738</td>\n",
       "      <td>17.565345</td>\n",
       "      <td>3.102997</td>\n",
       "      <td>7.592666</td>\n",
       "      <td>7.130097</td>\n",
       "      <td>3.145258</td>\n",
       "      <td>3.919426</td>\n",
       "      <td>...</td>\n",
       "      <td>2.844792</td>\n",
       "      <td>3.688047</td>\n",
       "      <td>7.160379</td>\n",
       "      <td>3.353631</td>\n",
       "      <td>6.005818</td>\n",
       "      <td>3.420561</td>\n",
       "      <td>6.603499</td>\n",
       "      <td>3.492548</td>\n",
       "      <td>5.774120</td>\n",
       "      <td>6.803984</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0.29940251144353242  -1.2266241875260637  1.4984250500215328  \\\n",
       "count           999.000000           999.000000          999.000000   \n",
       "mean              0.025322            -0.023323           -0.025612   \n",
       "std               1.008750             1.016094            0.978412   \n",
       "min              -3.365711            -3.492086           -2.695602   \n",
       "25%              -0.670358            -0.690859           -0.700048   \n",
       "50%               0.023121            -0.031181            0.008037   \n",
       "75%               0.762980             0.683464            0.657948   \n",
       "max               3.326246             3.583870            2.546507   \n",
       "\n",
       "       -1.1761503610375272  5.2898525545597037  0.20829711393323402  \\\n",
       "count           999.000000          999.000000           999.000000   \n",
       "mean             -0.001096            1.088127            -0.006465   \n",
       "std               0.970349            4.539161             0.989601   \n",
       "min              -3.460471          -16.421901            -3.041250   \n",
       "25%              -0.616548           -1.805683            -0.733114   \n",
       "50%               0.003735            0.858932             0.025803   \n",
       "75%               0.640968            3.836911             0.671494   \n",
       "max               3.088738           17.565345             3.102997   \n",
       "\n",
       "       2.4044983672405826  1.5945062220589785  -0.051608163273514231  \\\n",
       "count          999.000000          999.000000             999.000000   \n",
       "mean             0.495433           -0.039517               0.026469   \n",
       "std              2.119020            2.232776               1.001562   \n",
       "min             -7.224761           -6.509084              -3.145588   \n",
       "25%             -0.839542           -1.607010              -0.680114   \n",
       "50%              0.571475            0.017761               0.022855   \n",
       "75%              1.912284            1.436715               0.741949   \n",
       "max              7.592666            7.130097               3.145258   \n",
       "\n",
       "       0.66323431039687908         ...           -0.85046544625016463  \\\n",
       "count           999.000000         ...                     999.000000   \n",
       "mean             -0.004264         ...                       0.031533   \n",
       "std               1.013808         ...                       1.011767   \n",
       "min              -2.749812         ...                      -3.379194   \n",
       "25%              -0.682246         ...                      -0.659295   \n",
       "50%              -0.037531         ...                       0.049792   \n",
       "75%               0.666416         ...                       0.747815   \n",
       "max               3.919426         ...                       2.844792   \n",
       "\n",
       "       -0.62298999638261954  -1.8330573433160038  0.29302438506869571  \\\n",
       "count            999.000000           999.000000           999.000000   \n",
       "mean               0.023598            -0.541199            -0.011913   \n",
       "std                1.001668             2.240688             1.022922   \n",
       "min               -2.971125            -7.840890            -2.999564   \n",
       "25%               -0.696257            -2.123069            -0.664966   \n",
       "50%                0.050187            -0.568168            -0.028179   \n",
       "75%                0.700093             0.940334             0.651692   \n",
       "max                3.688047             7.160379             3.353631   \n",
       "\n",
       "       3.5526813410266507  0.71761099417552265  3.3059719748508889  \\\n",
       "count          999.000000           999.000000          999.000000   \n",
       "mean            -0.487548             0.032686            0.564443   \n",
       "std              2.118491             1.007316            2.227304   \n",
       "min             -7.124105            -2.952358           -5.452254   \n",
       "25%             -1.880040            -0.643513           -1.060154   \n",
       "50%             -0.493701             0.036975            0.453544   \n",
       "75%              0.997741             0.690139            2.120006   \n",
       "max              6.005818             3.420561            6.603499   \n",
       "\n",
       "       -2.7155588147154619  -2.6824085866346223  0.10105047232890663  \n",
       "count           999.000000           999.000000           999.000000  \n",
       "mean              0.009574            -0.890867             0.609960  \n",
       "std               0.994404             2.022240             2.046400  \n",
       "min              -3.473913            -8.051722            -7.799086  \n",
       "25%              -0.689890            -2.214672            -0.565156  \n",
       "50%               0.038464            -0.853259             0.780175  \n",
       "75%               0.693603             0.390982             1.994308  \n",
       "max               3.492548             5.774120             6.803984  \n",
       "\n",
       "[8 rows x 40 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.describe()    ######### (Great  --->  mean = 0 , standard deviation = 1,,     gaussian may be?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.73, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.82, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.82, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=0.8, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.73, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.78, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.83, total=   0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................................... , score=0.79, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.75, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ....................... , score=0.7272727272727273, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "/home/shuvambosana/.local/lib/python3.5/site-packages/sklearn/discriminant_analysis.py:682: UserWarning: Variables are collinear\n",
      "  warnings.warn(\"Variables are collinear\")\n"
     ]
    }
   ],
   "source": [
    "pred_KNN = KNN_Classifier(train_data,train_label,test_data)\n",
    "pred_SVM = SVM_Classifier(train_data,train_label,test_data)\n",
    "pred_GaussianNB = GaussianNB_Classifier(train_data,train_label,test_data)\n",
    "pred_RandomForest = RandomForest_Classifier(train_data,train_label,test_data)\n",
    "pred_QDA = QDA_Classifier(train_data,train_label,test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_CSV(pred_RandomForest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "########### Data Preprocessing Gaussian Mixture Model          No idea whats happening :(\n",
    "\n",
    "####### https://github.com/siddharthagarwal/Kaggle-Data-Science-London-Scikit-Learn/blob/master/london.py\n",
    "\n",
    "\n",
    "x_all = np.r_[train_data,test_data]           \n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "lowest_bic = np.infty\n",
    "bic = []\n",
    "n_components_range = range(1, 7)\n",
    "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
    "for cv_type in cv_types:\n",
    "    for n_components in n_components_range:\n",
    "        # Fit a mixture of Gaussians with EM\n",
    "        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n",
    "        gmm.fit(x_all)\n",
    "        bic.append(gmm.aic(x_all))\n",
    "        if bic[-1] < lowest_bic:\n",
    "            lowest_bic = bic[-1]\n",
    "            best_gmm = gmm\n",
    "            \n",
    "best_gmm.fit(x_all)\n",
    "\n",
    "x_train = best_gmm.predict_proba(train_data)\n",
    "x_test = best_gmm.predict_proba(test_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.99, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ..................................... , score=0.99, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n",
      "[CV]  ................................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.1s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] ..................................... , score=0.98, total=   0.0s\n",
      "[CV]  ................................................................\n",
      "[CV] ...................................... , score=1.0, total=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    }
   ],
   "source": [
    "#### using the GridSearchCV technique             Was expecting this library.. Phewwwww\n",
    "\n",
    "grid_search_rf = GridSearchCV(RandomForestClassifier(), param_grid=dict( ), verbose=3,scoring='accuracy',cv=10).fit(x_train,np.ravel(train_label))\n",
    "rf_best = grid_search_rf.best_estimator_\n",
    "\n",
    "rf_best.fit(x_train,np.ravel(train_label)) \n",
    "pred_rf = rf_best.predict(x_test)             #### Goddamn accuracy of 98.8%  Enough for me.. \n",
    "\n",
    "\n",
    "to_CSV(pred_rf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
